{
    "mem0": {
        "llm": {
            "provider": "ollama",
            "config": {
                "model": "llama3.1:8b",
                "temperature": 0.1,
                "max_tokens": 2000,
                "ollama_base_url": "http://host.docker.internal:11434"
            }
        },
        "embedder": {
            "provider": "ollama",
            "config": {
                "model": "nomic-embed-text:latest",
                "embedding_dims": 768,
                "ollama_base_url": "http://host.docker.internal:11434"
            }
        }
    }
}